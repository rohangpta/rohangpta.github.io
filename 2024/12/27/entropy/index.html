<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Ronalds Vilcins - https://grohan.co"><title>Technical Debt is Entropy In Software | Rohan Gupta</title><meta name=description content="Entropy"><meta name=twitter:card content="summary"><meta name=twitter:title content="Technical Debt is Entropy In Software"><meta name=twitter:description content="Entropy"><meta property="og:title" content="Technical Debt is Entropy In Software"><meta property="og:description" content="Entropy"><meta property="og:type" content="article"><meta property="og:url" content="https://grohan.co/2024/12/27/entropy/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-27T00:00:00+00:00"><meta itemprop=name content="Technical Debt is Entropy In Software"><meta itemprop=description content="Entropy"><meta itemprop=datePublished content="2024-12-27T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-27T00:00:00+00:00"><meta itemprop=wordCount content="1520"><meta itemprop=keywords content="tech,"><link rel=canonical href=https://grohan.co/2024/12/27/entropy/><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Rohan Gupta" href=https://grohan.coatom.xml><link rel=alternate type=application/json title="Rohan Gupta" href=https://grohan.cofeed.json><link rel=shortcuticon type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><script async src="https://www.googletagmanager.com/gtag/js?id=G-QPHTPNYLXE"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script>
<script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"]]}}</script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QPHTPNYLXE")</script><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 Verdana,-apple-system,BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeSpeed}.posts hr{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:none;border-bottom:1px #353535;flex:1 0 1rem}main{max-width:70ch;padding:2ch;margin:auto}a,body{color:#353535}::selection,a:focus,a:hover{background-color:#f0f0f0;color:#000}.meta{margin:0 0 2.5rem}.tags::before{content:"\2022";margin-left:1rem}code,pre{color:#353535;font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;border:1px solid #353535;font-size:small}code{padding:.1rem;border:none}pre{padding:.5rem;overflow-x:auto}pre code{border:none}img{max-width:100%;border:1px solid #353535}hr{background:#353535;height:1px;border:0}ul{list-style-type:square}ul,ol{padding-left:1.2rem}header li,footer li{display:inline;text-transform:uppercase}header a,footer a{text-decoration:none}header ul,footer ul{justify-content:space-between;display:flex}[aria-current=page]{text-decoration:line-through}header,section,footer{padding:1rem 0}blockquote{border-left:5px solid #353535;padding-left:1rem}.posts ul,header ul,footer ul{list-style:none}.posts,header ul,footer ul{padding:0}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.7rem}.posts li a,.posts li div{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}.hash{opacity:.25;text-decoration:none}table{border-collapse:collapse;text-align:left;width:100%}table tr{background:#fff;border-bottom:1px solid}table th,table td{padding:10px 20px}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Technical Debt is Entropy In Software","headline":"Technical Debt is Entropy In Software","alternativeHeadline":"","description":"Entropy","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/grohan.co\/2024\/12\/27\/entropy\/"},"author":{"@type":"Person","name":"Rohan Gupta"},"creator":{"@type":"Person","name":"Rohan Gupta"},"accountablePerson":{"@type":"Person","name":"Rohan Gupta"},"copyrightHolder":"Rohan Gupta","copyrightYear":"2024","dateCreated":"2024-12-27T00:00:00.00Z","datePublished":"2024-12-27T00:00:00.00Z","dateModified":"2024-12-27T00:00:00.00Z","publisher":{"@type":"Organization","name":"Rohan Gupta","url":"https://grohan.co","logo":{"@type":"ImageObject","url":"https:\/\/grohan.co\/images\/rohan.jpg","width":"32","height":"32"}},"image":"https://grohan.co/images/rohan.jpg","url":"https:\/\/grohan.co\/2024\/12\/27\/entropy\/","wordCount":"1520","genre":["tech"],"keywords":["tech"]}</script></head><body><main><header><nav><ul><li><a href=/posts aria-current=page>Writing</a></li><li><a href=/about>About</a></li><li><a href=/projects>Projects</a></li></ul></nav></header><hr><section><h2 itemprop="name headline">Technical Debt is Entropy In Software</h2><p class=meta><time itemprop=datePublished datetime=2024-12-27>December 27, 2024</time> &bull;
<a href=/tags/tech>tech</a></p><span itemprop=articleBody><h1 id=entropy>Entropy <a href=#entropy class=hash>#</a></h1><p>Entropy is the ultimate boss battle [1]. As the reason why ice melts, why tires
burst, and why ink diffuses &ndash; thermodynamic entropy is a fact of the
physical world, sharply following the arrow of time [2].</p><p>The Second Law of Thermodynamics states</p><blockquote><p>A system&rsquo;s entropy will either increase or remain the same over time, unless outside energy is added</p></blockquote><p>There&rsquo;s something about inevitability that I think is fascinating, especially
when you can see it unfold in front of you &ndash; my
favourite visualisation is below (thanks Gemini).</p><center><img src=/images/diffusion.png width=550 height=400></center><p>This picture displays the three stages of entropy:</p><ul><li><strong>Infancy</strong>: when the ink enters the water</li><li><strong>Expansion</strong>: when the ink diffuses through water</li><li><strong>Maturity</strong>: when the ink and water have fully merged</li></ul><p>So, how does entropy grow? Academics and practicioners alike believe that
entropy follows an S-curve [4], with its three stages likened to those of ink diffusing in water.</p><center><img src=/images/scurve.png width=550 height=400></center><p>This is strikingly similar to the business lifecycle curve above! Indeed, prior
art agrees that <strong>business and technology lifecycles are overlayed entropy curves</strong>
[5].</p><p>Entropy in business is largely a representation of diffusion of a
particular product, driven by the forces of supply and demand. While entropy is
often likened to &ldquo;disorder&rdquo;, I like to use &ldquo;disruption&rdquo; - permeation of new (ink)
into old (water). It is neither good nor bad, simply inevitable.</p><h2 id=properties-of-entropy>Properties of Entropy <a href=#properties-of-entropy class=hash>#</a></h2><h3 id=statistical-entropy>Statistical Entropy <a href=#statistical-entropy class=hash>#</a></h3><p>Since we are talking about software and not atoms, let&rsquo;s turn to information theory to
understand the information contained in software programs.</p><p>In information theory, Shannon&rsquo;s entropy is, for a random
variable \( X \) distributed according to \( p: (x \in \mathcal{X})
\rightarrow [0, 1] \):</p><p>$$ H(X) = - \sum_{x \in \mathcal{X}} p(x)\log(p(x)) $$</p><p>While this may look obscure at first, the formulation begets two properties:</p><ol><li><p><strong>Property 1.</strong> The number of possible states that a system can have is
generally proportional to the total entropy in a system. A dice with 6 sides has
more entropy than one with 4 sides.</p></li><li><p><strong>Property 2.</strong> Higher entropy is correlated with a higher likelihood of tail events.
Gaussians and exponentials are maximum entropy distributions (under
certain statistical conditions [3]). Both exhibit fat tail properties empirically.</p></li></ol><h3 id=complexity>Complexity <a href=#complexity class=hash>#</a></h3><p>Complexity is entropy&rsquo;s first cousin. Formally we&rsquo;ll use
Kolmogorov complexity:</p><blockquote><p>\(K(o)\) for an object \(o\) is the length of the shortest program that produces the
object as output.</p></blockquote><p>In other words, it measures how &ldquo;compressible&rdquo; something is.</p><p>Now - how does entropy relate to complexity? Modis posits the following relation [4][15]:</p><blockquote><p>Complexity is the time derivative of entropy. Given that entropy is an
S-curve, complexity is normally distributed.</p><p>With time, complexity increases until a peak and decreases after.</p></blockquote><p>To see this: let&rsquo;s consider Scott Aaronson&rsquo;s lucid example around cream dissolving
into coffee [6].</p><p>His research empirically calculated a complexity score using the <code>gzip</code> compression
file size of pictures of cream melting in the coffee.</p><center><img src=/images/coffee_complexity.png width=413 height=300></center><p>The picture above represents snapshots of the coffee cup at the three phases of entropy. As the cream and coffee begin to mix, complexity increases until a maximum
before decreasing as the mixture becomes saturated and homogeneous.</p><p>It is simple to see why the first and
last image can be more easily compressed (i.e are less complex) compared to the
image in the middle.</p><h1 id=where-does-software-fit-into-this>Where Does Software Fit Into This? <a href=#where-does-software-fit-into-this class=hash>#</a></h1><p>Let&rsquo;s start by quantifying where software is today in its business lifecycle /
entropy curve.</p><center><img src=/images/software_today.png width=550 height=400></center><p>As in the graph above, I think we are around (X,Y) today.</p><p>Why?</p><ul><li><p>Software is still custom-made / productised. SaaS &ldquo;exploded&rdquo; but hasn&rsquo;t permeated all
industries. Digital modernisation efforts continue to be in higher
demand than available supply, indicating superlinear business growth or relative
convexity &ndash; <em>close to the central inflection point</em>.</p></li><li><p>Software complexity is close to peaking. This one is bolstered by the
cloud driving successful commoditisation of infrastructure. We now have
the ability to <em>run software</em> cheaply and easily.</p><p>What&rsquo;s left is to reduce the complexity of
the specification of software (language and layers of
abstraction) that runs on said infrastructure. <em>Prediction</em>: LLMs are statistical
program compression tools [12] and will do exactly this.</p></li></ul><h1 id=tech-debt-as-complexity>Tech Debt as Complexity <a href=#tech-debt-as-complexity class=hash>#</a></h1><p>Technological modernisation is bottlenecked by iteration speed to a desired solution &ndash; and
tech debt is the maintenance and complexity related resistance to change.</p><p>The simplest description of tech debt that I&rsquo;ve been able to come up with has
two major forms.</p><h3 id=complexity-via-obscurity>Complexity via obscurity <a href=#complexity-via-obscurity class=hash>#</a></h3><p>Poorly designed software abstractions (obscurity) generate more complexity - &ldquo;garbage in, garbage
out&rdquo;.</p><p>The core issue with &ldquo;obscure&rdquo; abstractions is that they are uncompressed representations of state. That is, they encode more than they should.
Their interfaces are inherently complex, where they should instead be
simple and hide deep complexity [6] [11].</p><p>This results in programs that can have far more states than they should
(Property 1). Changing them means dealing with far more of these state transitions than you should!</p><h3 id=complexity-via-dense-dependency-graphs>Complexity via dense dependency graphs <a href=#complexity-via-dense-dependency-graphs class=hash>#</a></h3><p>Software that depends on A LOT of other software is more prone to bugs,
vulnerabilities, maintenance overhead, and change friction. This kind of
technical debt introduces some obscurity but also &ldquo;tail-risk&rdquo; around software (Property
2).</p><p>The number of failures due to weaknesses
in the open source parts of a software supply chain increased by 650% between
2020 and 2021 [8]. At the same time, OSS adoption grows 70% YoY [9], bringing with it
increasingly public vulnerabilities like in <code>log4j</code>, <code>xz</code>, <code>OpenSSH</code> etc.</p><p>What the entropy formula doesn&rsquo;t quite capture is how this &ldquo;tail-risk&rdquo; can very
often manifest as massively high-impact Black Swan events [14].</p><p>Massive cybercrimes affecting data
protection and financial security. Software outage affecting the
global economy. We&rsquo;ve all seen them play out.</p><h1 id=conclusion>Conclusion <a href=#conclusion class=hash>#</a></h1><center><img src=/images/complexity_entropy.png width=550 height=400></center><p>Since complexity is a differential snapshot of entropy in time, cumulative tech debt
is precisely the integral over all the complexity built up in software over history.</p><p>Further, given we are at the peak of complexity, we are at the peak of tech
debt&rsquo;s growth. <strong>It will inevitably slow down</strong>.</p><p>Intuitiviely, in the business “experimental -> custom -> product -> commodity” lifecycle,
software is at the custom/product intersection. In order to get from product to
commodity, it needs to be simpler and cheaper.</p><p>Economically, McKinsey estimates that tech debt accounts for 40% of IT balance
sheets and up to 50% of developer time [13]. It shows up as a vicious cycle that
organisations increasingly have a harder time escaping from (remember:
complexity begets complexity).</p><center><img src=/images/complexity_cycle.svgz width=550 height=400></center><p>A report on software quality in 2022 attaches a $1.5 trillion price tag
to technical debt in the form of poor quality and overly complex software [8].
However, if you interchange loosely with &ldquo;technological opportunity cost&rdquo;, the
real business value is of-course far
higher:</p><blockquote><p>The total technological debt includes entirely &ldquo;untapped&rdquo; digital transformation in industries + the canononical &ldquo;poorly tapped&rdquo; form of tech debt.</p></blockquote><p>A lot of words to say: there&rsquo;s a whole lot left to do here.</p><h1 id=footnotes-and-references>Footnotes and References <a href=#footnotes-and-references class=hash>#</a></h1><p>[1] <a href=https://x.com/elonmusk/status/1090689205586472960>https://x.com/elonmusk/status/1090689205586472960</a></p><p>[2] <a href=https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time>https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time</a></p><p>[3] <a href=https://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes08_infotheory.pdf>https://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes08_infotheory.pdf</a></p><p>[4] <a href=https://arxiv.org/abs/2410.10844>https://arxiv.org/abs/2410.10844</a></p><p>[5] <a href=http://www.growth-dynamics.com/articles/Forecasting_Complexity.pdf>http://www.growth-dynamics.com/articles/Forecasting_Complexity.pdf</a></p><p>[6] <a href=https://arxiv.org/abs/1405.6903>https://arxiv.org/abs/1405.6903</a></p><p>[7] <a href="https://books.google.com/books/about/A_Philosophy_of_Software_Design.html?id=hkfEzgEACAAJ&amp;source=kp_book_description">https://books.google.com/books/about/A_Philosophy_of_Software_Design.html?id=hkfEzgEACAAJ&amp;source=kp_book_description</a></p><p>[8] <a href=https://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf>https://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf</a></p><p>[9] <a href=https://www.sonatype.com/blog/the-scale-of-open-source-growth-challenges-and-key-insights>https://www.sonatype.com/blog/the-scale-of-open-source-growth-challenges-and-key-insights</a></p><p>[10] <a href=https://en.wikipedia.org/wiki/Lindy_effect>https://en.wikipedia.org/wiki/Lindy_effect</a></p><p>[11] <a href=https://en.wikipedia.org/wiki/Everything_is_a_file>https://en.wikipedia.org/wiki/Everything_is_a_file</a></p><p>[12] <a href=https://arxiv.org/abs/2309.10668>https://arxiv.org/abs/2309.10668</a></p><p>[13] <a href=https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/breaking-technical-debts-vicious-cycle-to-modernize-your-business>https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/breaking-technical-debts-vicious-cycle-to-modernize-your-business</a></p><p>[14] <a href=https://en.wikipedia.org/wiki/Black_swan_theory>https://en.wikipedia.org/wiki/Black_swan_theory</a></p><p>[15] Theodore Modis presents an excellent information-theoretic analysis of the relation between complexity
and entropy: his claim held true over a 20 year prediction (2002-2022) [4] (<em>a Lindy trend</em> [10]).</p><h1 id=appendix-three-hard-problems>Appendix: Three Hard Problems <a href=#appendix-three-hard-problems class=hash>#</a></h1><p>I&rsquo;ve spent a lot of words talking about a problem and tying it to other
problems. What does taming complexity look like? How do we roll the ball down
the peak of the hill?</p><p>At the risk of being tongue-in-cheek,
I&rsquo;ll start by saying I think the solution
will involve solving the &ldquo;three hardest problems&rdquo; in computer science.</p><h3 id=naming>Naming <a href=#naming class=hash>#</a></h3><p>Naming standards solve the literal naming problem. Today, standards
work - they just suffer from enforcement and distribution problems. Because of this, the shapes of
software abstractions haven&rsquo;t been globally standardised. It&rsquo;s a problem famous
enough to warrant its own <a href=https://xkcd.com/927/>obligatory XKCD</a>.</p><p>Because of where we are on the software S-curve, I suspect the move from product to commodity will
entail hiding the naming problem with higher-order abstractions. As people move
up an abstraction layer, user-defined names will simply matter less.</p><h3 id=caching>Caching <a href=#caching class=hash>#</a></h3><p>What&rsquo;s hard about caching isn&rsquo;t maintaining caching
infrastructure, but rather defining the correct cache key and invalidation
policy. This isn&rsquo;t impossible - it again just requires precise and
well-defined behaviour. The CPU caches are a great success story here - they
just needed maturity in the CPU/memory interface.</p><ul><li>With cacheability, you get reproducibility, determinism, and more general
fungibility of building blocks. With fungibility of building blocks - you
get commodity-like properties!</li><li>Declarative specifications of components are closely tied to cacheability -
a statement which traces the entire history of software infrastructure
growth and commoditisation (Kubernetes, Docker, Terraform, Nix, Bazel etc).</li></ul><h3 id=off-by-one-errors>Off by one errors <a href=#off-by-one-errors class=hash>#</a></h3><p>These simply represent human hallucinations. Execution
driven feedback. i.e unit test cases encapsulating abstractions &ldquo;solve&rdquo; this well.</p><h3 id=prove-it>Prove it? <a href=#prove-it class=hash>#</a></h3><p>I won&rsquo;t elaborate too much on &ldquo;solutions&rdquo; since I have various
hypotheses-in-testing that need iteration (as opposed to more ideation).</p><p>If you made it this far, clearly some of this was interesting to you. Let&rsquo;s chat! <a href=mailto:rohangupta883@gmail.com>Email</a> <a href=https://x.com/rohangupta_>X</a></p></span></section><hr><footer><nav><ul><li>© 2024</li></ul></nav></footer></main></body></html>