{"version":"https://jsonfeed.org/version/1","title":"Rohan Gupta","home_page_url":"https://grohan.co","feed_url":"https://ronaldsvilcins.com/feed.json","description":"Rohan Gupta's personal website","icon":"https://ronaldsvilcins.com/assets/apple-touch-icon.png","favicon":"https://ronaldsvilcins.com/assets/favicon.ico","expired":false,"author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"},"items":[{"id":"3d97b6cddc1764f4d41ae30637dd1ac7dc9acaaf","title":"Technical Debt is Entropy In Software","summary":"Entropy","content_text":"Entropy # Entropy is the ultimate boss battle [1]. As the reason why ice melts, why tires burst, and why ink diffuses \u0026ndash; thermodynamic entropy is a fact of the physical world, sharply following the arrow of time [2].\nThe Second Law of Thermodynamics states\nA system\u0026rsquo;s entropy will either increase or remain the same over time, unless outside energy is added\nThere\u0026rsquo;s something about inevitability that I think is fascinating, especially when you can see it unfold in front of you \u0026ndash; my favourite visualisation is below (thanks Gemini).\nThis picture displays the three stages of entropy:\nInfancy: when the ink enters the water Expansion: when the ink diffuses through water Maturity: when the ink and water have fully merged So, how does entropy grow? Academics and practicioners alike believe that entropy follows an S-curve [4], with its three stages likened to those of ink diffusing in water.\nThis is strikingly similar to the business lifecycle curve above! Indeed, prior art agrees that business and technology lifecycles are overlayed entropy curves [5].\nEntropy in business is largely a representation of diffusion of a particular product, driven by the forces of supply and demand. While entropy is often likened to \u0026ldquo;disorder\u0026rdquo;, I like to use \u0026ldquo;disruption\u0026rdquo; - permeation of new (ink) into old (water). It is neither good nor bad, simply inevitable.\nProperties of Entropy # Statistical Entropy # Since we are talking about software and not atoms, let\u0026rsquo;s turn to information theory to understand the information contained in software programs.\nIn information theory, Shannon\u0026rsquo;s entropy is, for a random variable \\( X \\) distributed according to \\( p: (x \\in \\mathcal{X}) \\rightarrow [0, 1] \\):\n$$ H(X) = - \\sum_{x \\in \\mathcal{X}} p(x)\\log(p(x)) $$\nWhile this may look obscure at first, the formulation begets two properties:\nProperty 1. The number of possible states that a system can have is generally proportional to the total entropy in a system. A dice with 6 sides has more entropy than one with 4 sides.\nProperty 2. Higher entropy is correlated with a higher likelihood of tail events. Gaussians and exponentials are maximum entropy distributions (under certain statistical conditions [3]). Both exhibit fat tail properties empirically.\nComplexity # Complexity is entropy\u0026rsquo;s first cousin. Formally we\u0026rsquo;ll use Kolmogorov complexity:\n\\(K(o)\\) for an object \\(o\\) is the length of the shortest program that produces the object as output.\nIn other words, it measures how \u0026ldquo;compressible\u0026rdquo; something is.\nNow - how does entropy relate to complexity? Modis posits the following relation [4][15]:\nComplexity is the time derivative of entropy. Given that entropy is an S-curve, complexity is normally distributed.\nWith time, complexity increases until a peak and decreases after.\nTo see this: let\u0026rsquo;s consider Scott Aaronson\u0026rsquo;s lucid example around cream dissolving into coffee [6].\nHis research empirically calculated a complexity score using the gzip compression file size of pictures of cream melting in the coffee.\nThe picture above represents snapshots of the coffee cup at the three phases of entropy. As the cream and coffee begin to mix, complexity increases until a maximum before decreasing as the mixture becomes saturated and homogeneous.\nIt is simple to see why the first and last image can be more easily compressed (i.e are less complex) compared to the image in the middle.\nWhere Does Software Fit Into This? # Let\u0026rsquo;s start by quantifying where software is today in its business lifecycle / entropy curve.\nAs in the graph above, I think we are around (X,Y) today.\nWhy?\nSoftware is still custom-made / productised. SaaS \u0026ldquo;exploded\u0026rdquo; but hasn\u0026rsquo;t permeated all industries. Digital modernisation efforts continue to be in higher demand than available supply, indicating superlinear business growth or relative convexity \u0026ndash; close to the central inflection point.\nSoftware complexity is close to peaking. This one is bolstered by the cloud driving successful commoditisation of infrastructure. We now have the ability to run software cheaply and easily.\nWhat\u0026rsquo;s left is to reduce the complexity of the specification of software (language and layers of abstraction) that runs on said infrastructure. Prediction: LLMs are statistical program compression tools [12] and will do exactly this.\nTech Debt as Complexity # Technological modernisation is bottlenecked by iteration speed to a desired solution \u0026ndash; and tech debt is the maintenance and complexity related resistance to change that causes this bottleneck.\nThe simplest description of tech debt that I\u0026rsquo;ve been able to come up with has two major forms.\nComplexity via obscurity # Poorly designed software abstractions (obscurity) generate more complexity - \u0026ldquo;garbage in, garbage out\u0026rdquo;.\nThe core issue with \u0026ldquo;obscure\u0026rdquo; abstractions is that they are uncompressed representations of state. That is, they encode more than they should. Their interfaces are inherently complex, where they should instead be simple and hide deep complexity [6] [11].\nThis results in programs that can have far more states than they should (Property 1). Changing them means dealing with far more of these state transitions than you should!\nComplexity via dense dependency graphs # Software that depends on A LOT of other software is more prone to bugs, vulnerabilities, maintenance overhead, and change friction. This kind of technical debt introduces some obscurity but also \u0026ldquo;tail-risk\u0026rdquo; around software (Property 2).\nThe number of failures due to weaknesses in the open source parts of a software supply chain increased by 650% between 2020 and 2021 [8]. At the same time, OSS adoption grows 70% YoY [9], bringing with it increasingly public vulnerabilities like in log4j, xz, OpenSSH etc.\nWhat the entropy formula doesn\u0026rsquo;t quite capture is how this \u0026ldquo;tail-risk\u0026rdquo; can very often manifest as massively high-impact Black Swan events [14].\nMassive cybercrimes affecting data protection and financial security. Software outage affecting the global economy. We\u0026rsquo;ve all seen them play out.\nConclusion # Since complexity is a differential snapshot of entropy in time, cumulative tech debt is precisely the integral over all the complexity built up in software over history.\nFurther, given we are at the peak of complexity, we are at the peak of tech debt\u0026rsquo;s growth. It will inevitably slow down.\nIntuitiviely, in the business “experimental -\u0026gt; custom -\u0026gt; product -\u0026gt; commodity” lifecycle, software is at the custom/product intersection. In order to get from product to commodity and therefore fully permeate society, it needs to be simpler and cheaper.\nEconomically, McKinsey estimates that tech debt accounts for 40% of IT balance sheets and up to 50% of developer time [13]. It shows up as a vicious cycle that organisations increasingly have a harder time escaping from (remember: complexity begets complexity).\nA report on software quality in 2022 attaches a $2.4 trillion price tag to technical debt in the form of poor quality and overly complex software [8]. However, if you interchange loosely with \u0026ldquo;technological opportunity cost\u0026rdquo;, the real business value is of-course far higher:\nThe total technological debt includes entirely \u0026ldquo;untapped\u0026rdquo; digital transformation in industries + the canononical \u0026ldquo;poorly tapped\u0026rdquo; form of tech debt.\nA lot of words to say: there\u0026rsquo;s a whole lot left to do here.\nFootnotes and References # [1] https://x.com/elonmusk/status/1090689205586472960\n[2] https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time\n[3] https://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes08_infotheory.pdf\n[4] https://arxiv.org/abs/2410.10844\n[5] http://www.growth-dynamics.com/articles/Forecasting_Complexity.pdf\n[6] https://arxiv.org/abs/1405.6903\n[7] https://books.google.com/books/about/A_Philosophy_of_Software_Design.html?id=hkfEzgEACAAJ\u0026amp;source=kp_book_description\n[8] https://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf\n[9] https://www.sonatype.com/blog/the-scale-of-open-source-growth-challenges-and-key-insights\n[10] https://en.wikipedia.org/wiki/Lindy_effect\n[11] https://en.wikipedia.org/wiki/Everything_is_a_file\n[12] https://arxiv.org/abs/2309.10668\n[13] https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/breaking-technical-debts-vicious-cycle-to-modernize-your-business\n[14] https://en.wikipedia.org/wiki/Black_swan_theory\n[15] Theodore Modis presents an excellent information-theoretic analysis of the relation between complexity and entropy: his claim held true over a 20 year prediction (2002-2022) [4] (a Lindy trend [10]).\nAppendix: Three Hard Problems # I\u0026rsquo;ve spent a lot of words talking about a problem and tying it to other problems. What does taming complexity look like? How do we roll the ball down the peak of the hill?\nAt the risk of being tongue-in-cheek, I\u0026rsquo;ll start by saying I think the solution will involve solving the \u0026ldquo;three hardest problems\u0026rdquo; in computer science.\nNaming # Naming standards solve the literal naming problem. Today, standards work - they just suffer from enforcement and distribution problems. Because of this, the shapes of software abstractions haven\u0026rsquo;t been globally standardised. It\u0026rsquo;s a problem famous enough to warrant its own obligatory XKCD.\nBecause of where we are on the software S-curve, I suspect the move from product to commodity will entail hiding the naming problem with higher-order abstractions. As people move up an abstraction layer, user-defined names will simply matter less.\nCaching # What\u0026rsquo;s hard about caching isn\u0026rsquo;t maintaining caching infrastructure, but rather defining the correct cache key and invalidation policy. This isn\u0026rsquo;t impossible - it again just requires precise and well-defined behaviour. The CPU caches are a great success story here - they just needed maturity in the CPU/memory interface.\nWith cacheability, you get reproducibility, determinism, and more general fungibility of building blocks. With fungibility of building blocks - you get commodity-like properties! Declarative specifications of components are closely tied to cacheability - a statement which traces the entire history of software infrastructure growth and commoditisation (Kubernetes, Docker, Terraform, Nix, Bazel etc). Off by one errors # These simply represent human hallucinations. Execution driven feedback. i.e unit test cases encapsulating abstractions \u0026ldquo;solve\u0026rdquo; this well.\nProve it? # I won\u0026rsquo;t elaborate too much on \u0026ldquo;solutions\u0026rdquo; since I have various hypotheses-in-testing that need iteration (as opposed to more ideation).\nIf you made it this far, clearly some of this was interesting to you. Let\u0026rsquo;s chat! Email X\n","content_html":"\u003ch1 id=\"entropy\"\u003eEntropy \u003ca href=\"#entropy\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eEntropy is the ultimate boss battle [1]. As the reason why ice melts, why tires\nburst, and why ink diffuses \u0026ndash; thermodynamic entropy is a fact of the\nphysical world, sharply following the arrow of time [2].\u003c/p\u003e\n\u003cp\u003eThe Second Law of Thermodynamics states\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA system\u0026rsquo;s entropy will either increase or remain the same over time, unless outside energy is added\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThere\u0026rsquo;s something about inevitability that I think is fascinating, especially\nwhen you can see it unfold in front of you \u0026ndash; my\nfavourite visualisation is below (thanks Gemini).\u003c/p\u003e\n\u003ccenter\u003e\u003cimg src =/images/diffusion.png width=\"550\" height=\"400\"/\u003e\u003c/center\u003e\n\u003cp\u003eThis picture displays the three stages of entropy:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInfancy\u003c/strong\u003e: when the ink enters the water\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExpansion\u003c/strong\u003e: when the ink diffuses through water\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMaturity\u003c/strong\u003e: when the ink and water have fully merged\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo, how does entropy grow? Academics and practicioners alike believe that\nentropy follows an S-curve [4], with its three stages likened to those of ink diffusing in water.\u003c/p\u003e\n\u003ccenter\u003e\u003cimg src =/images/scurve.png width=\"550\" height=\"400\"/\u003e \u003c/center\u003e\n\u003cp\u003eThis is strikingly similar to the business lifecycle curve above! Indeed, prior\nart agrees that \u003cstrong\u003ebusiness and technology lifecycles are overlayed entropy curves\u003c/strong\u003e\n[5].\u003c/p\u003e\n\u003cp\u003eEntropy in business is largely a representation of diffusion of a\nparticular product, driven by the forces of supply and demand. While entropy is\noften likened to \u0026ldquo;disorder\u0026rdquo;, I like to use \u0026ldquo;disruption\u0026rdquo; - permeation of new (ink)\ninto old (water). It is neither good nor bad, simply inevitable.\u003c/p\u003e\n\u003ch2 id=\"properties-of-entropy\"\u003eProperties of Entropy \u003ca href=\"#properties-of-entropy\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"statistical-entropy\"\u003eStatistical Entropy \u003ca href=\"#statistical-entropy\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eSince we are talking about software and not atoms, let\u0026rsquo;s turn to information theory to\nunderstand the information contained in software programs.\u003c/p\u003e\n\u003cp\u003eIn information theory, Shannon\u0026rsquo;s entropy is, for a random\nvariable  \\( X \\) distributed according to \\( p: (x \\in \\mathcal{X})\n\\rightarrow [0, 1] \\):\u003c/p\u003e\n\u003cp\u003e$$ H(X) = - \\sum_{x \\in \\mathcal{X}} p(x)\\log(p(x)) $$\u003c/p\u003e\n\u003cp\u003eWhile this may look obscure at first, the formulation begets two properties:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eProperty 1.\u003c/strong\u003e The number of possible states that a system can have is\ngenerally proportional to the total entropy in a system. A dice with 6 sides has\nmore entropy than one with 4 sides.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eProperty 2.\u003c/strong\u003e Higher entropy is correlated with a higher likelihood of tail events.\nGaussians and exponentials are maximum entropy distributions (under\ncertain statistical conditions [3]). Both exhibit fat tail properties empirically.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"complexity\"\u003eComplexity \u003ca href=\"#complexity\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eComplexity is entropy\u0026rsquo;s first cousin. Formally we\u0026rsquo;ll use\nKolmogorov complexity:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\\(K(o)\\) for an object \\(o\\) is the length of the shortest program that produces the\nobject as output.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIn other words, it measures how \u0026ldquo;compressible\u0026rdquo; something is.\u003c/p\u003e\n\u003cp\u003eNow - how does entropy relate to complexity? Modis posits the following relation [4][15]:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eComplexity is the time derivative of entropy. Given that entropy is an\nS-curve, complexity is normally distributed.\u003c/p\u003e\n\u003cp\u003eWith time, complexity increases until a peak and decreases after.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eTo see this: let\u0026rsquo;s consider Scott Aaronson\u0026rsquo;s lucid example around cream dissolving\ninto coffee [6].\u003c/p\u003e\n\u003cp\u003eHis research empirically calculated a complexity score using the \u003ccode\u003egzip\u003c/code\u003e compression\nfile size of pictures of cream melting in the coffee.\u003c/p\u003e\n\u003ccenter\u003e\u003cimg src =/images/coffee_complexity.png width=\"413\" height=\"300\"/\u003e\u003c/center\u003e\n\u003cp\u003eThe picture above represents snapshots of the coffee cup at the three phases of entropy. As the cream and coffee begin to mix, complexity increases until a maximum\nbefore decreasing as the mixture becomes saturated and homogeneous.\u003c/p\u003e\n\u003cp\u003eIt is simple to see why the first and\nlast image can be more easily compressed (i.e are less complex) compared to the\nimage in the middle.\u003c/p\u003e\n\u003ch1 id=\"where-does-software-fit-into-this\"\u003eWhere Does Software Fit Into This? \u003ca href=\"#where-does-software-fit-into-this\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eLet\u0026rsquo;s start by quantifying where software is today in its business lifecycle /\nentropy curve.\u003c/p\u003e\n\u003ccenter\u003e\u003cimg src =/images/software_today.png width=\"550\" height=\"400\"/\u003e\u003c/center\u003e\n\u003cp\u003eAs in the graph above, I think we are around (X,Y) today.\u003c/p\u003e\n\u003cp\u003eWhy?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSoftware is still custom-made / productised. SaaS \u0026ldquo;exploded\u0026rdquo; but hasn\u0026rsquo;t permeated all\nindustries. Digital modernisation efforts continue to be in higher\ndemand than available supply, indicating superlinear business growth or relative\nconvexity \u0026ndash; \u003cem\u003eclose to the central inflection point\u003c/em\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSoftware complexity is close to peaking. This one is bolstered by the\ncloud driving successful commoditisation of infrastructure. We now have\nthe ability to \u003cem\u003erun software\u003c/em\u003e cheaply and easily.\u003c/p\u003e\n\u003cp\u003eWhat\u0026rsquo;s left is to reduce the complexity of\nthe specification of software (language and layers of\nabstraction) that runs on said infrastructure. \u003cem\u003ePrediction\u003c/em\u003e: LLMs are statistical\nprogram compression tools [12] and will do exactly this.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"tech-debt-as-complexity\"\u003eTech Debt as Complexity \u003ca href=\"#tech-debt-as-complexity\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eTechnological modernisation is bottlenecked by iteration speed to a desired solution \u0026ndash; and\ntech debt is the maintenance and complexity related resistance to change that\ncauses this bottleneck.\u003c/p\u003e\n\u003cp\u003eThe simplest description of tech debt that I\u0026rsquo;ve been able to come up with has\ntwo major forms.\u003c/p\u003e\n\u003ch3 id=\"complexity-via-obscurity\"\u003eComplexity via obscurity \u003ca href=\"#complexity-via-obscurity\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003ePoorly designed software abstractions (obscurity) generate more complexity - \u0026ldquo;garbage in, garbage\nout\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eThe core issue with \u0026ldquo;obscure\u0026rdquo; abstractions is that they are uncompressed representations of state. That is, they encode more than they should.\nTheir interfaces are inherently complex, where they should instead be\nsimple and hide deep complexity [6] [11].\u003c/p\u003e\n\u003cp\u003eThis results in programs that can have far more states than they should\n(Property 1). Changing them means dealing with far more of these state transitions than you should!\u003c/p\u003e\n\u003ch3 id=\"complexity-via-dense-dependency-graphs\"\u003eComplexity via dense dependency graphs \u003ca href=\"#complexity-via-dense-dependency-graphs\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eSoftware that depends on A LOT of other software is more prone to bugs,\nvulnerabilities, maintenance overhead, and change friction. This kind of\ntechnical debt introduces some obscurity but also \u0026ldquo;tail-risk\u0026rdquo; around software (Property\n2).\u003c/p\u003e\n\u003cp\u003eThe number of failures due to weaknesses\nin the open source parts of a software supply chain increased by 650% between\n2020 and 2021 [8]. At the same time, OSS adoption grows 70% YoY [9], bringing with it\nincreasingly public vulnerabilities like in \u003ccode\u003elog4j\u003c/code\u003e, \u003ccode\u003exz\u003c/code\u003e, \u003ccode\u003eOpenSSH\u003c/code\u003e etc.\u003c/p\u003e\n\u003cp\u003eWhat the entropy formula doesn\u0026rsquo;t quite capture is how this \u0026ldquo;tail-risk\u0026rdquo; can very\noften manifest as massively high-impact Black Swan events [14].\u003c/p\u003e\n\u003cp\u003eMassive cybercrimes affecting data\nprotection and financial security. Software outage affecting the\nglobal economy. We\u0026rsquo;ve all seen them play out.\u003c/p\u003e\n\u003ch1 id=\"conclusion\"\u003eConclusion \u003ca href=\"#conclusion\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003ccenter\u003e\u003cimg src =/images/complexity_entropy.png width=\"550\" height=\"400\"/\u003e\u003c/center\u003e\n\u003cp\u003eSince complexity is a differential snapshot of entropy in time, cumulative tech debt\nis precisely the integral over all the complexity built up in software over history.\u003c/p\u003e\n\u003cp\u003eFurther, given we are at the peak of complexity, we are at the peak of tech\ndebt\u0026rsquo;s growth. \u003cstrong\u003eIt will inevitably slow down\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIntuitiviely, in the business “experimental -\u0026gt; custom -\u0026gt; product -\u0026gt; commodity” lifecycle,\nsoftware is at the custom/product intersection. In order to get from product to\ncommodity and therefore fully permeate society, it needs to be simpler and cheaper.\u003c/p\u003e\n\u003cp\u003eEconomically, McKinsey estimates that tech debt accounts for 40% of IT balance\nsheets and up to 50% of developer time [13]. It shows up as a vicious cycle that\norganisations increasingly have a harder time escaping from (remember:\ncomplexity begets complexity).\u003c/p\u003e\n\u003ccenter\u003e\u003cimg src =/images/complexity_cycle.svgz width=\"550\" height=\"400\"/\u003e\u003c/center\u003e\n\u003cp\u003eA report on software quality in 2022 attaches a $2.4 trillion price tag\nto technical debt in the form of poor quality and overly complex software [8].\nHowever, if you interchange loosely with \u0026ldquo;technological opportunity cost\u0026rdquo;, the\nreal business value is of-course far\nhigher:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe total technological debt includes entirely \u0026ldquo;untapped\u0026rdquo; digital transformation in industries + the canononical \u0026ldquo;poorly tapped\u0026rdquo; form of tech debt.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA lot of words to say: there\u0026rsquo;s a whole lot left to do here.\u003c/p\u003e\n\u003ch1 id=\"footnotes-and-references\"\u003eFootnotes and References \u003ca href=\"#footnotes-and-references\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e[1] \u003ca href=\"https://x.com/elonmusk/status/1090689205586472960\"\u003ehttps://x.com/elonmusk/status/1090689205586472960\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[2] \u003ca href=\"https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time\"\u003ehttps://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[3] \u003ca href=\"https://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes08_infotheory.pdf\"\u003ehttps://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes08_infotheory.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[4] \u003ca href=\"https://arxiv.org/abs/2410.10844\"\u003ehttps://arxiv.org/abs/2410.10844\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[5] \u003ca href=\"http://www.growth-dynamics.com/articles/Forecasting_Complexity.pdf\"\u003ehttp://www.growth-dynamics.com/articles/Forecasting_Complexity.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[6] \u003ca href=\"https://arxiv.org/abs/1405.6903\"\u003ehttps://arxiv.org/abs/1405.6903\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[7] \u003ca href=\"https://books.google.com/books/about/A_Philosophy_of_Software_Design.html?id=hkfEzgEACAAJ\u0026amp;source=kp_book_description\"\u003ehttps://books.google.com/books/about/A_Philosophy_of_Software_Design.html?id=hkfEzgEACAAJ\u0026amp;source=kp_book_description\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[8] \u003ca href=\"https://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf\"\u003ehttps://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[9] \u003ca href=\"https://www.sonatype.com/blog/the-scale-of-open-source-growth-challenges-and-key-insights\"\u003ehttps://www.sonatype.com/blog/the-scale-of-open-source-growth-challenges-and-key-insights\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[10] \u003ca href=\"https://en.wikipedia.org/wiki/Lindy_effect\"\u003ehttps://en.wikipedia.org/wiki/Lindy_effect\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[11] \u003ca href=\"https://en.wikipedia.org/wiki/Everything_is_a_file\"\u003ehttps://en.wikipedia.org/wiki/Everything_is_a_file\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[12] \u003ca href=\"https://arxiv.org/abs/2309.10668\"\u003ehttps://arxiv.org/abs/2309.10668\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[13] \u003ca href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/breaking-technical-debts-vicious-cycle-to-modernize-your-business\"\u003ehttps://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/breaking-technical-debts-vicious-cycle-to-modernize-your-business\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[14] \u003ca href=\"https://en.wikipedia.org/wiki/Black_swan_theory\"\u003ehttps://en.wikipedia.org/wiki/Black_swan_theory\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[15] Theodore Modis presents an excellent information-theoretic analysis of the relation between complexity\nand entropy: his claim held true over a 20 year prediction (2002-2022) [4] (\u003cem\u003ea Lindy trend\u003c/em\u003e [10]).\u003c/p\u003e\n\u003ch1 id=\"appendix-three-hard-problems\"\u003eAppendix: Three Hard Problems \u003ca href=\"#appendix-three-hard-problems\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eI\u0026rsquo;ve spent a lot of words talking about a problem and tying it to other\nproblems. What does taming complexity look like? How do we roll the ball down\nthe peak of the hill?\u003c/p\u003e\n\u003cp\u003eAt the risk of being tongue-in-cheek,\nI\u0026rsquo;ll start by saying I think the solution\nwill involve solving the \u0026ldquo;three hardest problems\u0026rdquo; in computer science.\u003c/p\u003e\n\u003ch3 id=\"naming\"\u003eNaming \u003ca href=\"#naming\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eNaming standards solve the literal naming problem. Today, standards\nwork - they just suffer from enforcement and distribution problems. Because of this, the shapes of\nsoftware abstractions haven\u0026rsquo;t been globally standardised. It\u0026rsquo;s a problem famous\nenough to warrant its own \u003ca href=\"https://xkcd.com/927/\"\u003eobligatory XKCD\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBecause of where we are on the software S-curve, I suspect the move from product to commodity will\nentail hiding the naming problem with higher-order abstractions. As people move\nup an abstraction layer, user-defined names will simply matter less.\u003c/p\u003e\n\u003ch3 id=\"caching\"\u003eCaching \u003ca href=\"#caching\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWhat\u0026rsquo;s hard about caching isn\u0026rsquo;t maintaining caching\ninfrastructure, but rather defining the correct cache key and invalidation\npolicy. This isn\u0026rsquo;t impossible - it again just requires precise and\nwell-defined behaviour. The CPU caches are a great success story here - they\njust needed maturity in the CPU/memory interface.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWith cacheability, you get reproducibility, determinism, and more general\nfungibility of building blocks. With fungibility of building blocks - you\nget commodity-like properties!\u003c/li\u003e\n\u003cli\u003eDeclarative specifications of components are closely tied to cacheability -\na statement which traces the entire history of software infrastructure\ngrowth and commoditisation (Kubernetes, Docker, Terraform, Nix, Bazel etc).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"off-by-one-errors\"\u003eOff by one errors \u003ca href=\"#off-by-one-errors\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThese simply represent human hallucinations. Execution\ndriven feedback. i.e unit test cases encapsulating abstractions \u0026ldquo;solve\u0026rdquo; this well.\u003c/p\u003e\n\u003ch3 id=\"prove-it\"\u003eProve it? \u003ca href=\"#prove-it\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eI won\u0026rsquo;t elaborate too much on \u0026ldquo;solutions\u0026rdquo; since I have various\nhypotheses-in-testing that need iteration (as opposed to more ideation).\u003c/p\u003e\n\u003cp\u003eIf you made it this far, clearly some of this was interesting to you. Let\u0026rsquo;s chat! \u003ca href=\"mailto:rohangupta883@gmail.com\"\u003eEmail\u003c/a\u003e \u003ca href=\"https://x.com/rohangupta_\"\u003eX\u003c/a\u003e\u003c/p\u003e\n","url":"https://grohan.co/2024/12/27/entropy/","image":"https://grohan.cophotos/<no value>","banner_image":"https://grohan.cophotos/<no value>","date_published":"27126-27-09T120:2727:00+00:00","date_modified":"27126-27-09T120:2727:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"46ef1ef941af4eccb00a5fe986a02f0b51a08a78","title":"Factorials \u0026 Fun with Vim","summary":"Vim trix and more","content_text":"I recently hit a somewhat important milestone in my life: one year as a Vim user. Despite its steep learning curve, I used to think that mastering Vim was mostly about habit formation. I swore by the cheatsheets and believed I would be golden. After all, a text editor couldn\u0026rsquo;t be too terribly complex, right?\nHowever, I soon realised how little I knew about Vim and how much there really was to know! In writing this post, I\u0026rsquo;d like to demonstrate (by way of example) some of the features of Vim that I found interesting; this is by no means a comprehensive guide to Vim\u0026rsquo;s capabilities (I would be lying if I said I knew half of what Vim has to offer), but perhaps a newfound taste of power for the green, fresh-off-VS Code individual looking to dabble with the dark arts.\nComputing Factorials # This post has a simple goal: computing the factorial. A classic exercise for any new programmer \u0026ndash; simple to understand, but broad in terms of concepts covered. More formally, we\u0026rsquo;ll define our problem as writing a Vim routine that takes an input (ex. 5!) and spits out the factorial (120 in our example).\nAs a preface, I\u0026rsquo;ll be referencing a variety of Vim features in this post, but I\u0026rsquo;m explicitly choosing not to explain their usage in detail. Instead, I\u0026rsquo;ve tried to link resources that explain syntax and functionality better than I can. This is not a tutorial as much as it is a showcase.\nState Transitions and Math # To break our problem down a bit, we need a way to multiply (and decrement) numbers in Vim, store the results somewhere, and then repeat that process N times. Sounds simple enough?\nThankfully, we don\u0026rsquo;t have to implement multiplication from scratch. Vim\u0026rsquo;s got us covered here with the expression register, noted by \u0026ldquo;=\u0026rdquo;. You can access this in insert mode using \u0026lt;C-r\u0026gt;= and enter any expression you\u0026rsquo;d like. The expression register is clever enough to do basic math operations (addition, subtraction, multiplication, division), but not the factorial \u0026ndash; unfortunately our life isn\u0026rsquo;t that easy.\nAs an example, you could enter insert mode and input \u0026lt;C-r\u0026gt;=10*7 and the text under your cursor will be filled with 70, neat enough for simple calculations on the fly.\nSo we\u0026rsquo;ve got a way to multiply numbers, now we need to do this recursively as well as store intermediate state somewhere. Let\u0026rsquo;s tackle the state problem first; for the sake of demonstration, we\u0026rsquo;ll do the most naive thing I can think of to store our intermediate state: write to text.\nConsider a program with the following states\n7! 6!7 5!42 4!210 ... 5040 The contents after the ! store the intermediate state of the program, while leaving the contents before valid for recursion. We now effectively have program memory equal to the size of the text buffer we\u0026rsquo;re working with!\nWith our states defined, we\u0026rsquo;ve now got to think about how exactly we transition between these states. This is where we can introduce the Vim substitute command, which matches against patterns and replaces them according to a set of rules.\nThe command below matches on a number a followed by ! and replaces it with (a-1)!a. This is our base case for the recursion. We use the . operator to concatenate our expressions (using the expression register) together. We\u0026rsquo;re also able to use submatch(0) which simply matches against everything captured.\n:s/\\d\\+!/\\=submatch(0) - 1 . \u0026#34;!\u0026#34; . submatch(0)/ Next, we need our \u0026ldquo;recursive case\u0026rdquo;, matching on a!b and replacing with a-1!b*a. Note the introduction of capturing groups below! Previously, we only matched on one set of characters but now we have 2 distinct operations, which is also why we use indices 1 and 2 for submatch.\n:s/\\(\\d\\+\\)!\\(\\d\\+\\)/\\=submatch(1) - 1 . \u0026#34;!\u0026#34; . submatch(1) \\* submatch(2)/ Fantastic! This will take 6!7 and map it to 5!42, and so on.\nOrchestration # We\u0026rsquo;ve got all the state transformations we need now, but we still need a way to somehow orchestrate them together in a single command. This includes finding a way to programmatically recurse on our substitution expression a variable number of times. Sounds like a lot, but Vim\u0026rsquo;s again got us covered with an idiomatic tool: the macro, which is essentially a way to record sequences of edits and apply them in one shot.\nOur script now looks like this (we record the macro in the @b register):\nV :s/\\d\\+!/\\=submatch(0) - 1 . \u0026#34;!\u0026#34; . submatch(0)/ qb V :s/\\(\\d\\+\\)!\\(\\d\\+\\)/\\=submatch(1) - 1 . \u0026#34;!\u0026#34; . submatch(1) \\* submatch(2)/ q Nearly done, now all we need is a way to find the number of times to execute the macro. Until now, we\u0026rsquo;ve been on a purist edit-only streak, but let\u0026rsquo;s instead introduce some real programming concepts (variables!?).\nlet i = matchstr(getline(\u0026#39;.\u0026#39;), \u0026#39;\\d\\+\u0026#39;) execute \u0026#34;normal! \u0026#34; . i . \u0026#34;@b\u0026#34; These two lines will execute our macro i times, where i is simply the value of the number we want to compute the factorial of.\nFinally, this will leave us with 1!5040 (in the case of 7!). We need to perform just a bit of cleanup, since we have some extra information in the line (corresponding to our state), which we can do with the following substitution logic:\n:s/.\\*!\\(\\d\\+\\)/\\1/ or alternatively, using globals (note the use of the Vim exclusive look-ahead \\ze)\n:g/.\\*!\\ze/normal! df! And that\u0026rsquo;s it! Combining all of these expressions together gives us a general factorial machine.\nNote: I\u0026rsquo;m certainly aware of neater/shorter/better ways to do the same thing but I wanted to go through as many different \u0026ldquo;Vim trix\u0026rdquo; as I could in a post. If you\u0026rsquo;re looking to optimise for neatness and flex your Vim muscles, you might want to check out Vim Golf. I\u0026rsquo;m convinced some of the folks on there are not human.\nMeans to an End # The purpose of this post is not to encourage the reader to leave their trusted calculator behind in favour of Vim, but instead to view a multi-stage programming problem under the lens of powerful, expressive edits.\nVim, like many other programming tools, is primarily a means to an end. It simply happens to be powerful enough to do almost anything under the sun (if you are determined and/or crazy enough).\nWhat\u0026rsquo;s also remarkable to me is how Vim (circa 1991) has squarely stood its ground in the everchanging landscape of software development tools. Perhaps this is a testament to the timeless quality of design decisions made \u0026ndash; a seemingly rare feat in the fast-paced modern world of software. There\u0026rsquo;s a long way to go before I consider myself an expert at Vim, and I\u0026rsquo;m not sure if there truly is an end in sight; but perhaps that\u0026rsquo;s what makes it a fun tool to use?\nP.S.: I write fondly about Vim but I should mention that I\u0026rsquo;m actually an Emacs user. Plot twist, I know. My editor of choice is Doom Emacs which is a smooth, Space-centric Emacs config with Vim emulation. Why fight over Emacs vs Vim when you can have both?\nFurther Reading # I realise as I write this post that a lot of what I\u0026rsquo;ve written about involves Vim regex. Here\u0026rsquo;s an article I found online that does a good job explaining it.\nI\u0026rsquo;m often reminded of this legendary answer which captures the essence of what I think makes Vim so enduringly good: powerful expressivity combined with a simplistic grammar.\nLastly, here is a well-written epitaph to Bram Moolenar (the creator of Vim).\n","content_html":"\u003cp\u003eI recently hit a somewhat important milestone in my life: one year as a Vim\nuser. Despite its steep learning curve, I used to think that mastering Vim\nwas mostly about habit formation. I swore by the\ncheatsheets and believed I would be golden. After all, a\ntext editor couldn\u0026rsquo;t be too terribly complex, right?\u003c/p\u003e\n\u003cp\u003eHowever, I soon realised how \u003cem\u003elittle\u003c/em\u003e I knew about Vim and how much there\nreally was to know! In writing this post, I\u0026rsquo;d like to demonstrate (by\nway of example) some of\nthe features of Vim that I found interesting; this is by no means a\ncomprehensive guide to Vim\u0026rsquo;s capabilities (I would be lying if I said I knew half of what Vim\nhas to offer), but perhaps a newfound \u003ca href=\"https://xkcd.com/378/\"\u003etaste of power\u003c/a\u003e\nfor the green, fresh-off-VS Code individual looking to dabble with the dark arts.\u003c/p\u003e\n\u003ch1 id=\"computing-factorials\"\u003eComputing Factorials \u003ca href=\"#computing-factorials\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eThis post has a simple goal: computing the factorial. A classic exercise for any\nnew programmer \u0026ndash; simple to understand, but broad in terms of concepts covered.\nMore formally, we\u0026rsquo;ll define our problem as writing a Vim routine that takes an input (ex. 5!) and spits out the factorial (120 in our example).\u003c/p\u003e\n\u003cp\u003eAs a preface, I\u0026rsquo;ll be referencing a variety of Vim features in this post, but I\u0026rsquo;m explicitly choosing not to explain their usage in detail. Instead, I\u0026rsquo;ve tried to link resources that explain syntax and functionality better than I can. This is not a tutorial as much as it is a showcase.\u003c/p\u003e\n\u003ch2 id=\"state-transitions-and-math\"\u003eState Transitions and Math \u003ca href=\"#state-transitions-and-math\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eTo break our problem down a bit, we need a way to multiply (and decrement) numbers in Vim, store the results somewhere, and then repeat that process N times. Sounds simple enough?\u003c/p\u003e\n\u003cp\u003eThankfully, we don\u0026rsquo;t have to implement multiplication from scratch. Vim\u0026rsquo;s got us covered here with the \u003ca href=\"https://stackoverflow.com/questions/7027741/what-is-the-purpose-of-the-expression-register\"\u003eexpression register\u003c/a\u003e, noted by \u0026ldquo;=\u0026rdquo;. You can access this in insert mode using \u003ccode\u003e\u0026lt;C-r\u0026gt;=\u003c/code\u003e and enter any expression you\u0026rsquo;d like. The expression register is clever enough to do basic math operations (addition, subtraction, multiplication, division), but not the factorial \u0026ndash; unfortunately\nour life isn\u0026rsquo;t \u003cem\u003ethat\u003c/em\u003e easy.\u003c/p\u003e\n\u003cp\u003eAs an example, you could enter insert mode and input \u003ccode\u003e\u0026lt;C-r\u0026gt;=10*7\u003c/code\u003e and the text under your cursor will be filled with 70, neat enough for simple calculations on the fly.\u003c/p\u003e\n\u003cp\u003eSo we\u0026rsquo;ve got a way to multiply numbers, now we need to do this recursively as\nwell as store intermediate state somewhere. Let\u0026rsquo;s tackle the state problem\nfirst; for the sake of demonstration, we\u0026rsquo;ll do the most naive thing I can think\nof to store our intermediate state: write to text.\u003c/p\u003e\n\u003cp\u003eConsider a program with the following states\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e7!\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e6!7\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e5!42\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e4!210\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e...\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e5040\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe contents after the ! store the intermediate state of the program, while leaving the contents before valid for recursion. We now effectively have program memory equal to the size of the text buffer we\u0026rsquo;re working with!\u003c/p\u003e\n\u003cp\u003eWith our states defined, we\u0026rsquo;ve now got to think about how exactly we transition between these states. This is where we can introduce the Vim \u003ca href=\"https://vim.fandom.com/wiki/Search_and_replace\"\u003esubstitute\u003c/a\u003e command, which matches against patterns and replaces them according to a set of rules.\u003c/p\u003e\n\u003cp\u003eThe command below matches on a number \u003ccode\u003ea\u003c/code\u003e followed by ! and replaces it with \u003ccode\u003e(a-1)!a\u003c/code\u003e. This is our base case for the recursion. We use the \u003ccode\u003e.\u003c/code\u003e operator to concatenate our expressions (using the expression register) together. We\u0026rsquo;re also able to use \u003ccode\u003esubmatch(0)\u003c/code\u003e which simply matches against everything captured.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:s/\\d\\+!/\\=submatch(0) - 1 . \u0026#34;!\u0026#34; . submatch(0)/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNext, we need our \u0026ldquo;recursive case\u0026rdquo;, matching on \u003ccode\u003ea!b\u003c/code\u003e and replacing with \u003ccode\u003ea-1!b*a\u003c/code\u003e. Note the introduction of capturing groups below! Previously, we only matched on one set of characters but now we have 2 distinct operations, which is also why we use indices 1 and 2 for \u003ccode\u003esubmatch\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:s/\\(\\d\\+\\)!\\(\\d\\+\\)/\\=submatch(1) - 1 . \u0026#34;!\u0026#34; . submatch(1) \\* submatch(2)/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eFantastic! This will take 6!7 and map it to 5!42, and so on.\u003c/p\u003e\n\u003ch2 id=\"orchestration\"\u003eOrchestration \u003ca href=\"#orchestration\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWe\u0026rsquo;ve got all the state transformations we need now, but we still need a way to somehow orchestrate them together in a single command. This includes finding a way to programmatically recurse on our substitution expression a variable number of times. Sounds like a lot, but Vim\u0026rsquo;s again got us covered with an idiomatic tool: \u003ca href=\"https://vim.fandom.com/wiki/Macros\"\u003ethe macro\u003c/a\u003e, which is essentially a way to record sequences of edits and apply them in one shot.\u003c/p\u003e\n\u003cp\u003eOur script now looks like this (we record the macro in the \u003ccode\u003e@b\u003c/code\u003e register):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eV\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:s/\\d\\+!/\\=submatch(0) - 1 . \u0026#34;!\u0026#34; . submatch(0)/\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eqb\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eV\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:s/\\(\\d\\+\\)!\\(\\d\\+\\)/\\=submatch(1) - 1 . \u0026#34;!\u0026#34; . submatch(1) \\* submatch(2)/\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eq\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNearly done, now all we need is a way to find the number of times to execute the macro. Until now, we\u0026rsquo;ve been on a purist edit-only streak, but let\u0026rsquo;s instead introduce some \u003cem\u003ereal\u003c/em\u003e programming concepts (variables!?).\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elet i = matchstr(getline(\u0026#39;.\u0026#39;), \u0026#39;\\d\\+\u0026#39;)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexecute \u0026#34;normal! \u0026#34; . i . \u0026#34;@b\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThese two lines will execute our macro \u003ccode\u003ei\u003c/code\u003e times, where \u003ccode\u003ei\u003c/code\u003e is simply the value of the number we want to compute the factorial of.\u003c/p\u003e\n\u003cp\u003eFinally, this will leave us with 1!5040 (in the case of 7!). We need to perform just a bit of cleanup, since we have some extra information in the line (corresponding to our state), which we can do with the following substitution logic:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:s/.\\*!\\(\\d\\+\\)/\\1/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eor alternatively, using \u003ca href=\"https://vim.fandom.com/wiki/Power_of_g\"\u003eglobals\u003c/a\u003e (note the use of the Vim exclusive look-ahead \u003ccode\u003e\\ze\u003c/code\u003e)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e:g/.\\*!\\ze/normal! df!\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAnd that\u0026rsquo;s it! Combining all of these expressions together gives us a general factorial machine.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: I\u0026rsquo;m certainly aware of neater/shorter/better ways to do the same thing\nbut I wanted to go through as many different \u0026ldquo;Vim trix\u0026rdquo; as I could in a post. If\nyou\u0026rsquo;re looking to optimise for neatness and flex your Vim muscles, you might want to check out \u003ca href=\"https://vimgolf.com\"\u003eVim Golf\u003c/a\u003e. I\u0026rsquo;m convinced some of the folks on there are not human.\u003c/p\u003e\n\u003ch2 id=\"means-to-an-end\"\u003eMeans to an End \u003ca href=\"#means-to-an-end\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThe purpose of this post is not to encourage the reader to leave\ntheir trusted calculator behind in favour of Vim, but instead to view a\nmulti-stage programming problem under the lens of powerful, expressive edits.\u003c/p\u003e\n\u003cp\u003eVim, like many other programming tools, is primarily a means to an end. It\nsimply happens to be powerful enough to do almost anything under the sun (if you are determined and/or\ncrazy enough).\u003c/p\u003e\n\u003cp\u003eWhat\u0026rsquo;s also remarkable to me is how Vim (circa 1991) has squarely stood its ground in the everchanging landscape of software development tools. Perhaps this is a testament to the timeless quality of design\ndecisions made \u0026ndash; a seemingly rare feat in the fast-paced modern world of\nsoftware. There\u0026rsquo;s a long way to go before I consider myself an expert at Vim, and I\u0026rsquo;m not\nsure if there truly is an end in sight; but perhaps that\u0026rsquo;s what makes it a fun\ntool to use?\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eP.S.\u003c/em\u003e: I write fondly about Vim but I should mention that I\u0026rsquo;m actually\nan Emacs user. Plot twist, I know. My editor of choice is \u003ca href=\"https://github.com/doomemacs/doomemacs\"\u003eDoom Emacs\u003c/a\u003e which\nis a smooth, Space-centric Emacs config with Vim emulation. Why fight over\nEmacs vs Vim when you can have both?\u003c/p\u003e\n\u003ch2 id=\"further-reading\"\u003eFurther Reading \u003ca href=\"#further-reading\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eI realise as I write this post that a lot of what I\u0026rsquo;ve written about involves Vim regex.\nHere\u0026rsquo;s an \u003ca href=\"https://dev.to/iggredible/learning-vim-regex-26ep\"\u003earticle\u003c/a\u003e I found\nonline that does a good job explaining it.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m often reminded of \u003ca href=\"https://stackoverflow.com/questions/1218390/what-is-your-most-productive-shortcut-with-vim/1220118#1220118\"\u003ethis legendary\nanswer\u003c/a\u003e\nwhich captures the essence of what I think makes Vim so enduringly good:\npowerful expressivity combined with a simplistic grammar.\u003c/p\u003e\n\u003cp\u003eLastly, here is a \u003ca href=\"https://j11g.com/2023/08/07/the-legacy-of-bram-moolenaar/\"\u003ewell-written epitaph\u003c/a\u003e to Bram Moolenar (the creator of Vim).\u003c/p\u003e\n","url":"https://grohan.co/2023/08/10/vim/","image":"https://grohan.cophotos/<no value>","banner_image":"https://grohan.cophotos/<no value>","date_published":"10086-10-09T80:1010:00+00:00","date_modified":"10086-10-09T80:1010:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}},{"id":"a77c2c5d4d187c889fa2442bb6b1bd728e96248a","title":"Halfway There","summary":"Reflection on first 2 years of college","content_text":"College. Times of fun, frolic, and of course, learning. For a couple days now, I\u0026rsquo;ve been thinking about the past 2 years of my life, focusing on the most meaningful aspects. I needed a place to write my reflections down, so I thought perhaps this would make for a fitting first blog post. So here\u0026rsquo;s a couple shoddily jotted down thoughts on what I think have been my most significant takeaways from school, so far.\nSchool still sucks, but less # I used to absolutely despise highschool. Part of it was because I was a lazy slob who wanted to play RuneScape every waking hour but mostly because I didn\u0026rsquo;t like what I was meant to do in school in order to do well. For example, the Computer Science curriculum tested us on some pretty jank stuff. We\u0026rsquo;re talking definitions, case studies, and the most basic OOP. I\u0026rsquo;d spend hours the morning of the exam rote learning the names of 7 layers of the OSI model, but not what they actually were useful for.\nWhen I got to college, I was hoping that I would be, for the most part, doing things that I enjoyed, and those things would directly correlate to how well I was doing. This turned out to be initially true! I felt pretty academically satisfied after my first year of school, but (to my unfortunate realization) it just happened to be that intro classes at Penn are run especially well. Not only do they teach you real CS fundamentals, but they also have fun, knowledgeable folks on staff and run a great curriculum that kept me engaged with the material. (aside: I was pleasantly surprised to learn early freshman year that CIS 1xx staff are pretty tight-knit. They even do BYOs \u0026ndash; I know, not what you\u0026rsquo;d think when I mention CS course staff)\nAs I progressed to some of the upper division classes, I was still learning interesting things, but it felt like I was increasingly falling into the habit of autodidactism. For example, I took CIS 521: Artificial Intelligence sophomore fall. The class was, by all metrics, good, but there was no sense of community or engagement as in the intro classes. Crucially, it could be done async and had annoying assignments. The in-person equivalent just didn\u0026rsquo;t seem valuable enough to go to. I could just Google any questions I had and, well, kind of figure things out as I go. This left me thinking \u0026ndash; if I really cared about the material, I could have just as easily put my head down and grinded out the class (which was basically a bunch of videos) in a couple weeks, skipping over the poorly designed bits. I ended up attending zero (0) live lectures for the class \u0026ndash; I don\u0026rsquo;t even know what room it was in.\nIs that the way I like learning? I\u0026rsquo;m not sure. But one thing is for sure: it\u0026rsquo;s convenient. Since Fall 2021, I\u0026rsquo;ve been going to almost no classes, because it is simply more convenient to learn material at home, at my own pace. There\u0026rsquo;s probably some joke out there about 1.5x lectures being the new norm, but at this point it\u0026rsquo;s reality. I have been living on 1.5x and lecture notes.\nWhile the convenience is certainly nice, it\u0026rsquo;s unfulfilling. I had hoped college would be more of the interactive, community-oriented experience I had in my intro classes. For the few upper division classes that do offer this, great. But for the others, if someone were to download the Canvas page and send it over to me to cherry-pick modules, I think I\u0026rsquo;d have a better time than having to go through administrative nonsense, annoying homeworks, and even more annoying exams \u0026ndash; I\u0026rsquo;m taking most of this upper level stuff for fun anyways.\nFor the most part, school isn\u0026rsquo;t the one \u0026ldquo;teaching\u0026rdquo; me, I\u0026rsquo;m learning things myself. But with the added overhead of whatever the course staff decides is going to make up my grade. Let me do this stuff on my own, or run classes better and make people want to show up!\nI actually like what I do now # I don\u0026rsquo;t like the question: what are your hobbies? A hobby sounds far too casual for me. I\u0026rsquo;m the type of person who finds one thing and then does it obsessively. In highschool, I played a lot of RuneScape. Like a lot. ~300 full days worth of RuneScape. You can do the math yourself, but that\u0026rsquo;s a large number of hours. (fun fact: I only told my mother this number after I got into college, she still wasn\u0026rsquo;t amused). RuneScape was, truly, what I did \u0026ndash; the thing I would think about on the hour long bus ride back from school, and often sneak late at night to do instead of whatever homework I had due.\nBut it wasn\u0026rsquo;t the most practical or interesting (to most people). Indeed, it\u0026rsquo;s pretty difficult to sit down at dinner with someone and explain why a game that\u0026rsquo;s older than I am and not very well known was so captivating to me. So, well, if someone asked me my hobbies were or what I did, I\u0026rsquo;d look them in the eye, lie through my teeth, and say that I was into Computer Science. But, at the time (in highschool) that wasn\u0026rsquo;t really true.\nFor context, my first legitimate introduction to real-world programming was the summer after sophomore year. I was unquestioningly forced to go make use of myself at my mother\u0026rsquo;s hospital\u0026rsquo;s IT department, where I was tasked with building some nonsense webapp using everyone\u0026rsquo;s favourite web framework: Django. I didn\u0026rsquo;t know the first thing about web programming so I began prowling through Django documentation. I didn\u0026rsquo;t really understand everything, but I understood enough to combine with code from GitHub and StackOverFlow and piece together something that just about worked.\nThe problem was: I didn\u0026rsquo;t really care about understanding more, or learning about the things I was working with. For example, I didn\u0026rsquo;t know what HTTP was, just that you could do a bunch of operations with it, like GET and POST, and those operations did exactly what you\u0026rsquo;d think they did. Instead, I wanted to play RuneScape, or laze around, or watch some show, or eat Indian McDonald\u0026rsquo;s Mexican Cheesy Fries (I miss this a lot). Coding was alright, I could do it if I was really asked to, and I wasn\u0026rsquo;t terrible at it, but it didn\u0026rsquo;t really make me tick.\nFlash-forward to freshman fall at Penn. I come in as a Cognitive Science major. I mean, brains seemed cool. I half-assed a Coursera course on ML sometime senior year of highschool, so AI also seemed cool. I\u0026rsquo;d also worked with computers. It seemed natural to study Cognitive Science, but I wasn\u0026rsquo;t the guy with a plan. On a whim, I saw that Penn Labs used Django, and it seemed somewhat interesting, so I thought I\u0026rsquo;d give it a shot. By some miracle, things work out and I get in. In a week\u0026rsquo;s time, I realize that I\u0026rsquo;ve been lying to myself.\nEveryone at the club seemed so genuinely passionate about computers, it was nuts \u0026ndash; they actually cared about how things worked. The folks I worked with actually knew what HTTP was, and that was the least of the things they knew about. Strange words like DevOps, Docker, Kubernetes would float around in Slack, and I\u0026rsquo;d have no idea what they meant. Debugging wasn\u0026rsquo;t just Googling and copypasting on loop, but actually trying things meaningfully. I felt pretty out of place \u0026ndash; a small fish in a big pond \u0026ndash; but I liked it!\nNot only was I learning a lot, but the enthusiasm for programming was rubbing off on me. Experiencing this alongside the intro CS classes I talked about above, I actually began to enjoy computer science. I found myself Googling random things about Django in my free time, searching up about tools like pipenv, and doing things that the younger me would never have done. I was experiencing a shift in the thing I did: from RuneScape to coding.\nThings end up panning out after: I transfer to NETS, get more involved with Labs, learn about those strange words I mentioned above through CIS 188, and generally immerse myself in the programming world. However, looking back, it\u0026rsquo;s funny how things work out sometimes \u0026ndash; I\u0026rsquo;ve often reflected on the fact that the 10 person IT department in a hospital in Bangalore, India just happened to use Django as their backend, which is perhaps the only reason I thought I\u0026rsquo;d have a shot at Penn Labs, and consequently end up growing as much as I did.\nTo conclude, I\u0026rsquo;d like to note that the title is a little misleading, I\u0026rsquo;ve always liked what I really did, but I definitely did fake it for a bit. Now, when I\u0026rsquo;m at a dinner, and I\u0026rsquo;m prompted about my hobbies, it\u0026rsquo;s a little more gratifying to say that I like programming \u0026ndash; because I know it is for real.\n","content_html":"\u003cp\u003eCollege. Times of fun, frolic, and of course, learning. For a couple days now,\nI\u0026rsquo;ve been thinking about the past 2 years of my life, focusing on the most\nmeaningful aspects. I needed a place to write my reflections down, so\nI thought perhaps this would make for a fitting first blog post. So here\u0026rsquo;s a\ncouple shoddily jotted down thoughts on what I think have been my most\nsignificant takeaways from school, so far.\u003c/p\u003e\n\u003ch1 id=\"school-still-sucks-but-less\"\u003eSchool still sucks, but less \u003ca href=\"#school-still-sucks-but-less\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eI used to absolutely despise highschool. Part of it was because I was a lazy\nslob who wanted to play RuneScape every waking hour but mostly because I didn\u0026rsquo;t\nlike what I was meant to do in school in order to do well. For example, the\nComputer Science curriculum tested us on some pretty jank stuff. We\u0026rsquo;re talking\ndefinitions, case studies, and the most basic OOP. I\u0026rsquo;d spend hours the morning\nof the exam rote learning the names of 7 layers of the OSI model, but not what\nthey \u003cem\u003eactually\u003c/em\u003e were useful for.\u003c/p\u003e\n\u003cp\u003eWhen I got to college, I was hoping that I would be, for the most part, doing\nthings that I enjoyed, and those things would directly correlate to how well I\nwas doing. This turned out to be initially true! I felt pretty academically\nsatisfied after my first year of school, but (to my unfortunate realization) it\njust happened to be that intro classes at Penn are run especially well. Not only\ndo they teach you real CS fundamentals, but they also have fun, knowledgeable\nfolks on staff and run a great curriculum that kept me engaged with the\nmaterial. (aside: I was pleasantly surprised to learn early freshman year that\nCIS 1xx staff are pretty tight-knit. They even do BYOs \u0026ndash; I know, not what you\u0026rsquo;d\nthink when I mention CS course staff)\u003c/p\u003e\n\u003cp\u003eAs I progressed to some of the upper division classes, I was still learning\ninteresting things, but it felt like I was increasingly falling into the habit\nof autodidactism. For example, I took \u003cstrong\u003eCIS 521: Artificial Intelligence\u003c/strong\u003e\nsophomore fall. The class was, by all metrics, good, but there was no sense of\ncommunity or engagement as in the intro classes. Crucially, it \u003cem\u003ecould be done\nasync and had annoying assignments\u003c/em\u003e. The in-person equivalent just didn\u0026rsquo;t seem\nvaluable enough to go to. I could just Google any questions I had and, well,\nkind of figure things out as I go. This left me thinking \u0026ndash; if I really cared\nabout the material, I could have just as easily put my head down and grinded out\nthe class (which was basically a bunch of videos) in a couple weeks, skipping\nover the poorly designed bits. I ended up attending zero (0) live lectures for\nthe class \u0026ndash; I don\u0026rsquo;t even know what room it was in.\u003c/p\u003e\n\u003cp\u003eIs that the way I like learning? I\u0026rsquo;m not sure. But one thing is for sure: it\u0026rsquo;s\nconvenient. Since Fall 2021, I\u0026rsquo;ve been going to almost no classes, because it is\nsimply more convenient to learn material at home, at my own pace. There\u0026rsquo;s\nprobably some joke out there about 1.5x lectures being the new norm, but at this\npoint it\u0026rsquo;s reality. I have been \u003cem\u003eliving\u003c/em\u003e on 1.5x and lecture notes.\u003c/p\u003e\n\u003cp\u003eWhile the convenience is certainly nice, it\u0026rsquo;s unfulfilling. I had hoped college\nwould be more of the interactive, community-oriented experience I had in my\nintro classes. For the few upper division classes that do offer this, great. But\nfor the others, if someone were to download the Canvas page and send it over to\nme to cherry-pick modules, I think I\u0026rsquo;d have a better time than having to go\nthrough administrative nonsense, annoying homeworks, and even more annoying\nexams \u0026ndash; I\u0026rsquo;m taking most of this upper level stuff for fun anyways.\u003c/p\u003e\n\u003cp\u003eFor the most part, school isn\u0026rsquo;t the one \u0026ldquo;teaching\u0026rdquo; me, I\u0026rsquo;m learning things\nmyself. But with the added overhead of whatever the course staff decides is\ngoing to make up my grade. Let me do this stuff on my own, or run classes better\nand make people want to show up!\u003c/p\u003e\n\u003c!--- markdown auto fill mode ---\u003e\n\u003ch1 id=\"i-actually-like-what-i-_do_-now\"\u003eI actually like what I \u003cem\u003edo\u003c/em\u003e now \u003ca href=\"#i-actually-like-what-i-_do_-now\" class=\"hash\"\u003e#\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eI don\u0026rsquo;t like the question: what are your hobbies? A hobby sounds far too casual\nfor me. I\u0026rsquo;m the type of person who finds one thing and then \u003cem\u003edoes\u003c/em\u003e it\nobsessively. In highschool, I played a lot of RuneScape. Like a lot. ~300 full\ndays worth of RuneScape. You can do the math yourself, but that\u0026rsquo;s a large number\nof hours. (fun fact: I only told my mother this number after I got\ninto college, she still wasn\u0026rsquo;t amused). RuneScape was, truly, what I \u003cem\u003edid\u003c/em\u003e \u0026ndash; the thing\nI would think about on the hour long bus ride back from school, and often sneak\nlate at night to do instead of whatever homework I had due.\u003c/p\u003e\n\u003cp\u003eBut it wasn\u0026rsquo;t the most practical or interesting (to most people). Indeed, it\u0026rsquo;s\npretty difficult to sit down at dinner with someone and explain why a game\nthat\u0026rsquo;s older than I am and not very well known was so captivating to me. So,\nwell, if someone asked me my hobbies were or what I \u003cem\u003edid\u003c/em\u003e, I\u0026rsquo;d look them in the\neye, lie through my teeth, and say that I was into Computer Science. But, at\nthe time (in highschool) that wasn\u0026rsquo;t really true.\u003c/p\u003e\n\u003cp\u003eFor context, my first legitimate introduction to real-world programming was the summer\nafter sophomore year. I was unquestioningly forced to go make use of myself at\nmy mother\u0026rsquo;s hospital\u0026rsquo;s IT department, where I was tasked with building some\nnonsense webapp using everyone\u0026rsquo;s favourite web framework: Django. I didn\u0026rsquo;t know\nthe first thing about web programming so I began prowling through Django\ndocumentation. I didn\u0026rsquo;t really understand everything, but I understood enough to\ncombine with code from GitHub and StackOverFlow and piece together something\nthat just about worked.\u003c/p\u003e\n\u003cp\u003eThe problem was: I didn\u0026rsquo;t really \u003cem\u003ecare\u003c/em\u003e about understanding more, or learning\nabout the things I was working with. For example, I didn\u0026rsquo;t know what \u003ccode\u003eHTTP\u003c/code\u003e was,\njust that you could do a bunch of operations with it, like \u003ccode\u003eGET\u003c/code\u003e and \u003ccode\u003ePOST\u003c/code\u003e, and\nthose operations did exactly what you\u0026rsquo;d think they did. Instead, I wanted to\nplay RuneScape, or laze around, or watch some show, or eat Indian McDonald\u0026rsquo;s\n\u003ca href=\"https://mcdonaldsblog.in/wp-content/uploads/2016/11/mexican-fries.jpg\"\u003eMexican Cheesy\nFries\u003c/a\u003e (I\nmiss this a lot). Coding was alright, I could do it if I was really asked to,\nand I wasn\u0026rsquo;t terrible at it, but it didn\u0026rsquo;t really make me tick.\u003c/p\u003e\n\u003cp\u003eFlash-forward to freshman fall at Penn. I come in as a Cognitive Science major.\nI mean, brains seemed cool. I half-assed a Coursera course on ML sometime senior\nyear of highschool, so AI also seemed cool. I\u0026rsquo;d also worked with computers. It\nseemed natural to study Cognitive Science, but I wasn\u0026rsquo;t the guy with a plan. On\na whim, I saw that \u003ca href=\"https://pennlabs.org\"\u003ePenn Labs\u003c/a\u003e used Django, and it seemed\nsomewhat interesting, so I thought I\u0026rsquo;d give it a shot. By some miracle, things\nwork out and I get in. In a week\u0026rsquo;s time, I realize that I\u0026rsquo;ve been lying to\nmyself.\u003c/p\u003e\n\u003cp\u003eEveryone at the club seemed so genuinely passionate about computers, it was nuts\n\u0026ndash; they actually cared about how things worked. The folks I worked with actually knew\nwhat \u003ccode\u003eHTTP\u003c/code\u003e was, and that was the least of the things they knew about. Strange\nwords like \u003ccode\u003eDevOps, Docker, Kubernetes\u003c/code\u003e would float around in Slack, and I\u0026rsquo;d\nhave no idea what they meant. Debugging wasn\u0026rsquo;t just Googling and copypasting on\nloop, but actually trying things meaningfully. I felt pretty out of place \u0026ndash; a\nsmall fish in a big pond \u0026ndash; but I liked it!\u003c/p\u003e\n\u003cp\u003eNot only was I learning a lot, but the enthusiasm for programming was rubbing\noff on me. Experiencing this alongside the intro CS classes I talked about\nabove, I actually began to enjoy computer science. I found myself Googling\nrandom things about Django in my free time, searching up about tools like\n\u003ccode\u003epipenv\u003c/code\u003e, and doing things that the younger me would never have done. I was\nexperiencing a shift in the thing I \u003cem\u003edid\u003c/em\u003e: from RuneScape to coding.\u003c/p\u003e\n\u003cp\u003eThings end up panning out after: I transfer to \u003ca href=\"https://www.nets.upenn.edu/\"\u003eNETS\u003c/a\u003e, get\nmore involved with Labs, learn about those strange words I mentioned above through\n\u003ca href=\"https://cis188.org/\"\u003eCIS 188\u003c/a\u003e, and generally immerse myself in the programming\nworld. However, looking back, it\u0026rsquo;s funny how things work out sometimes \u0026ndash; I\u0026rsquo;ve often reflected on the fact\nthat the 10 person IT department in a hospital in Bangalore, India just happened\nto use Django as their backend, which is perhaps the only reason I thought I\u0026rsquo;d\nhave a shot at Penn Labs, and consequently end up growing as much as I did.\u003c/p\u003e\n\u003cp\u003eTo conclude, I\u0026rsquo;d like to note that the title is a little misleading, I\u0026rsquo;ve always\nliked what I \u003cstrong\u003ereally\u003c/strong\u003e did, but I definitely did fake it for a bit. Now, when\nI\u0026rsquo;m at a dinner, and I\u0026rsquo;m prompted about my hobbies, it\u0026rsquo;s a little more\ngratifying to say that I like programming \u0026ndash; because I know it is for real.\u003c/p\u003e\n","url":"https://grohan.co/2022/06/15/halfway/","image":"https://grohan.cophotos/<no value>","banner_image":"https://grohan.cophotos/<no value>","date_published":"15066-15-09T60:1515:00+00:00","date_modified":"15066-15-09T60:1515:00+00:00","author":{"name":"Ronalds Vilcins","url":"https://ronaldsvilcins.com/"}}]}